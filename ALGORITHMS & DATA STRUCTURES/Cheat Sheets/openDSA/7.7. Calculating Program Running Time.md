## A - Reglas para Simplificar el Análisis de Algoritmos (Simplifying Rules for Algorithm Analysis)

#### 1. **Definición:**

Cuando analizamos cuánto tiempo tarda un programa, a menudo usamos la notación "Big O" para simplificar las cosas. Estas reglas nos ayudan a hacer ese análisis más fácil y rápido. Imagina que estamos viendo cómo crece el tiempo de ejecución de un programa a medida que aumenta la cantidad de datos que procesa (n).

**Reglas Clave:**

1.  **Transitividad:** Si una función `f(n)` no crece más rápido que `g(n)` (en términos de Big O), y `g(n)` no crece más rápido que `h(n)`, entonces `f(n)` tampoco crece más rápido que `h(n)`. En cristiano: Si A es más pequeño que B, y B es más pequeño que C, entonces A es más pequeño que C. _(En inglés: If f(n) is in O(g(n)) and g(n) is in O(h(n)), then f(n) is in O(h(n)))_
2.  **Constantes Multiplicativas:** Si multiplicas una función `g(n)` por un número constante positivo `k`, no cambia su "orden de crecimiento" en Big O. Es decir, `O(kg(n))` es lo mismo que `O(g(n))`. En cristiano: Si algo tarda `5 * n` tiempo, sigue siendo lineal, como si tardara `n` tiempo. _(En inglés: If f(n) is in O(kg(n)) for any constant k>0, then f(n) is in O(g(n)))_
3.  **Suma de Funciones:** Si tienes dos partes de un programa, una que tarda `O(g1(n))` y otra que tarda `O(g2(n))`, el tiempo total del programa será del orden del máximo entre `O(g1(n))` y `O(g2(n))`. En cristiano: Si una parte tarda tiempo lineal `n` y otra cuadrático `n^2`, el total será cuadrático `n^2` porque es el que más crece. _(En inglés: If f1(n) is in O(g1(n)) and f2(n) is in O(g2(n)), then f1(n)+f2(n) is in O(max(g1(n),g2(n))))_
4.  **Producto de Funciones:** Si una operación se repite dentro de otra, y la primera tarda `O(g1(n))` y la segunda `O(g2(n))`, el tiempo total será `O(g1(n) * g2(n))`. En cristiano: Si tienes un bucle dentro de otro bucle, y ambos dependen de `n`, el tiempo total será como `n * n = n^2`. _(En inglés: If f1(n) is in O(g1(n)) and f2(n) is in O(g2(n)), then f1(n)f2(n) is in O(g1(n)g2(n)))_

#### 2. **Ejemplo:**

Imagina que tienes un programa con dos partes:

- Parte 1: Un bucle que recorre `n` elementos una vez. Tiempo: `O(n)`.
- Parte 2: Otro bucle que también recorre `n` elementos, pero dentro de otro bucle que se repite 3 veces. Tiempo: `O(3n)`.

Usando la regla 2, `O(3n)` es lo mismo que `O(n)`. Usando la regla 3, el tiempo total del programa es `O(max(n, n)) = O(n)`.

#### 3. **Notas o advertencias:**

- Estas reglas son para simplificar el análisis y enfocarnos en cómo el tiempo de ejecución _crece_ con la entrada, no en los tiempos exactos.
- Las constantes (como el '3' en `O(3n)`) se ignoran en la notación Big O porque lo que importa es la tendencia a largo plazo cuando `n` se hace muy grande.

---

## B - Análisis de Fragmentos de Código Comunes (Analyzing Common Code Fragments)

#### 1. **Asignación Simple (Simple Assignment):**

##### **1. Definición:**

Una simple asignación de valor a una variable.

##### **2. Ejemplo:**

```java
a = b;
```

```cpp
a = b;
```

**Explicación del ejemplo:**
Asignar un valor a una variable toma una cantidad de tiempo constante, sin importar el tamaño de la entrada `n`.

##### **3. Tiempo de Ejecución:**

Θ(1) - Tiempo constante. _(En inglés: Constant time)_

#### 2. **Bucle `for` Simple (Simple `for` loop):**

##### **1. Definición:**

Un bucle que se ejecuta un número de veces que depende de `n`.

##### **2. Ejemplo:**

```java
sum = 0;
for (int i = 1; i <= n; i++) {
   sum += n;
}
```

```cpp
sum = 0;
for (int i = 1; i <= n; i++)
   sum += n;
```

**Explicación del ejemplo:**

- `sum = 0;` se ejecuta una vez (tiempo constante).
- El bucle `for` se repite `n` veces.
- `sum += n;` dentro del bucle se ejecuta en tiempo constante cada vez.

##### **3. Tiempo de Ejecución:**

Θ(n) - Tiempo lineal. _(En inglés: Linear time)_

#### 3. **Bucles `for` Anidados (Nested `for` loops):**

##### **1. Definición:**

Un bucle `for` dentro de otro bucle `for`.

##### **2. Ejemplo 1: Bucle doble estándar**

```java
sum = 0;
for (int j = 1; j <= n; j++) {
  for (int i = 1; i <= j; i++) {
    sum++;
  }
}
```

```cpp
sum = 0;
for (int j = 1; j <= n; j++)
   for (int i = 1; i <= j; i++)
      sum++;
```

**Explicación del ejemplo:**

- El bucle exterior se ejecuta `n` veces.
- El bucle interior se ejecuta `j` veces, y `j` cambia desde 1 hasta `n`.
- `sum++` se ejecuta un número de veces que es la suma de 1 + 2 + 3 + ... + n, que es `n*(n+1)/2`.

##### **3. Tiempo de Ejecución del Ejemplo 1:**

Θ(n<sup>2</sup>) - Tiempo cuadrático. _(En inglés: Quadratic time)_

##### **2. Ejemplo 2: Bucle doble con ambos bucles hasta `n`**

```java
sum1 = 0;
for (int i = 1; i <= n; i++) {
  for (int j = 1; j <= n; j++) {
    sum1++;
  }
}
```

```cpp
sum1 = 0;
for (int i = 1; i <= n; i++)
   for (int j = 1; j <= n; j++)
      sum1++;
```

**Explicación del ejemplo:**

- El bucle exterior se ejecuta `n` veces.
- El bucle interior se ejecuta _siempre_ `n` veces, sin importar el valor de `i`.
- `sum1++` se ejecuta `n * n = n^2` veces.

##### **3. Tiempo de Ejecución del Ejemplo 2:**

Θ(n<sup>2</sup>) - Tiempo cuadrático. _(En inglés: Quadratic time)_

##### **3. Ejemplo 3: Bucle doble con incremento exponencial en el bucle exterior**

```java
sum1 = 0;
for (int k = 1; k <= n; k *= 2) {
  for (int j = 1; j <= n; j++) {
    sum1++;
  }
}
```

```cpp
sum1 = 0;
for (int k = 1; k <= n; k *= 2)
   for (int j = 1; j <= n; j++)
      sum1++;
```

**Explicación del ejemplo:**

- El bucle exterior se ejecuta aproximadamente `log₂(n)` veces (porque `k` se duplica en cada paso hasta que supera `n`).
- El bucle interior se ejecuta `n` veces en cada iteración del bucle exterior.
- `sum1++` se ejecuta aproximadamente `n * log₂(n)` veces.

##### **3. Tiempo de Ejecución del Ejemplo 3:**

Θ(n log n) - Tiempo lineal logarítmico. _(En inglés: Linearithmic time)_

##### **4. Ejemplo 4: Bucle doble con incremento exponencial en el bucle exterior y límite dependiente**

```java
sum2 = 0;
for (int k = 1; k <= n; k *= 2) {
  for (int j = 1; j <= k; j++) {
    sum2++;
  }
}
```

```cpp
sum2 = 0;
for (int k = 1; k <= n; k *= 2)
   for (int j = 1; j <= k; j++)
      sum2++;
```

**Explicación del ejemplo:**

- El bucle exterior se ejecuta aproximadamente `log₂(n)` veces.
- El bucle interior se ejecuta `k` veces, y `k` se duplica en cada paso del bucle exterior (1, 2, 4, 8, ..., hasta cerca de `n`).
- `sum2++` se ejecuta 1 + 2 + 4 + 8 + ... + (aproximadamente `n`) veces. Esta suma es aproximadamente igual a `n`.

##### **3. Tiempo de Ejecución del Ejemplo 4:**

Θ(n) - Tiempo lineal. _(En inglés: Linear time)_

#### 4. **Otros Controles de Flujo (Other Control Statements):**

- **Bucles `while` (While loops):** Se analizan de forma similar a los bucles `for`. Cuenta cuántas veces se ejecuta el cuerpo del bucle.
- **Sentencias `if` (If statements):** En el peor caso, el tiempo es el máximo entre el bloque `then` (si se cumple la condición) y el bloque `else` (si no se cumple).
- **Sentencias `switch` (Switch statements):** El peor caso es el tiempo del caso más largo (`case`).
- **Llamadas a subrutinas/funciones (Subroutine calls):** Suma el tiempo que tarda la función llamada al tiempo del resto del código.

---

## C - Análisis de Funciones Recursivas (Analyzing Recursive Functions)

#### 1. **Definición:**

Las funciones recursivas son funciones que se llaman a sí mismas. Para analizar su tiempo de ejecución, a menudo usamos **relaciones de recurrencia**. Una relación de recurrencia describe el tiempo de ejecución de una función en términos del tiempo de ejecución para entradas más pequeñas.

#### 2. **Ejemplo: Función Factorial Recursiva (Recursive Factorial Function):**

##### **1. Definición de la función factorial recursiva:**

La función factorial de `n` (n!) se define como `n * (n-1)!` para `n > 1`, y `1! = 1`. Recursivamente, se calcula multiplicando `n` por el factorial de `n-1`.

##### **2. Relación de Recurrencia para el tiempo de ejecución T(n):**

```
T(n) = T(n-1) + 1  para n > 1
T(1) = 0
```

**Explicación de la relación de recurrencia:**

- `T(n)` es el tiempo para calcular el factorial de `n`.
- `T(n-1)` es el tiempo para la llamada recursiva con `n-1`.
- `+ 1` representa el tiempo constante para la multiplicación de `n` por el resultado de `T(n-1)`.
- `T(1) = 0` es el caso base: calcular el factorial de 1 no requiere más llamadas recursivas (en términos de multiplicaciones, si contamos multiplicaciones).

##### **3. Solución de la Relación de Recurrencia:**

La solución a esta relación de recurrencia es Θ(n). Esto significa que el tiempo de ejecución de la función factorial recursiva crece linealmente con `n`.

**Visualización de la recurrencia:**

![Recurrence Tree](https://opendsa-server.cs.vt.edu/ODSA/Books/Everything/html/_static/Images/Recurrence.png)

**Explicación de la imagen:**
Cada nivel del árbol representa una llamada recursiva. En cada nivel, se hace un trabajo constante (+1). Hay `n` niveles (desde `n` hasta 1). Por lo tanto, el trabajo total es proporcional a `n`.

#### 3. **Notas o advertencias:**

- Resolver relaciones de recurrencia puede ser más complicado para funciones recursivas más complejas.
- Existen técnicas como el "método maestro" para resolver ciertas formas comunes de relaciones de recurrencia.

---

## D - Estudio de Caso: Dos Algoritmos de Búsqueda (Case Study: Two Search Algorithms)

#### 1. **Búsqueda Secuencial (Sequential Search):**

##### **1. Definición:**

Revisar cada elemento de un array uno por uno hasta encontrar el valor buscado o llegar al final del array.

##### **2. Tiempo de Ejecución:**

- **Peor caso y caso promedio:** Θ(n) - Tiempo lineal. En el peor de los casos, tienes que revisar todos los `n` elementos.

#### 2. **Búsqueda Binaria (Binary Search):**

##### **1. Definición:**

Un algoritmo mucho más eficiente para buscar en un array _ordenado_. Funciona dividiendo repetidamente a la mitad la porción del array que podría contener el valor, hasta reducir las posibles ubicaciones a solo una.

##### **2. Visualización de Búsqueda Binaria:**

![Binary Search Visualization](https://opendsa-server.cs.vt.edu/ODSA/Books/Everything/html/_static/Images/BinarySearch.gif)

**Explicación de la imagen:**
La animación muestra cómo la búsqueda binaria reduce el espacio de búsqueda a la mitad en cada paso. Se busca el número 45 en un array ordenado.

##### **3. Algoritmo (Pseudocódigo):**

```
funcion busquedaBinaria(array A, valor K):
    bajo = 0
    alto = longitud(A) - 1
    mientras bajo <= alto:
        medio = (bajo + alto) / 2
        si A[medio] < K:
            bajo = medio + 1  // Buscar en la mitad derecha
        sino si A[medio] > K:
            alto = medio - 1  // Buscar en la mitad izquierda
        sino: // A[medio] == K
            retornar medio     // Encontrado!
    retornar "no encontrado"
```

##### **4. Relación de Recurrencia para el tiempo de ejecución T(n) de la Búsqueda Binaria:**

```
T(n) = T(n/2) + 1  para n > 1
T(1) = 1
```

**Explicación de la relación de recurrencia:**

- `T(n)` es el tiempo para buscar en un array de tamaño `n`.
- `T(n/2)` es el tiempo para la llamada recursiva en la mitad del array.
- `+ 1` representa el tiempo constante para comparar el valor medio y ajustar los límites `bajo` o `alto`.
- `T(1) = 1` es el caso base: buscar en un array de tamaño 1 toma tiempo constante.

##### **5. Tiempo de Ejecución:**

- **Peor caso:** Θ(log n) - Tiempo logarítmico. La búsqueda binaria es _mucho_ más rápida que la búsqueda secuencial para arrays grandes.

#### 3. **Trade-offs (Ventajas y Desventajas):**

- **Búsqueda Binaria es más rápida (Θ(log n)) que la Búsqueda Secuencial (Θ(n))** para arrays grandes.
- **Requisito de la Búsqueda Binaria:** El array debe estar _ordenado_. Ordenar un array lleva tiempo (por ejemplo, con algoritmos de ordenamiento eficientes como mergesort o quicksort, toma O(n log n) en promedio).
- **Búsqueda Secuencial no requiere que el array esté ordenado.**

**Conclusión:** Si vas a realizar muchas búsquedas en un array y puedes permitirte ordenarlo una vez (o mantenerlo ordenado mientras se insertan elementos), la búsqueda binaria es una excelente opción. Si solo vas a hacer unas pocas búsquedas o el array cambia constantemente y reordenarlo es muy costoso, la búsqueda secuencial podría ser suficiente o incluso mejor en algunos casos. Todo depende del contexto de tu problema.
