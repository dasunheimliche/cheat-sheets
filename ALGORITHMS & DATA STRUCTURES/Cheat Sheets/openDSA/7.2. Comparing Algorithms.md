## A - ¿Por qué comparar algoritmos?

#### 1. **Definición:**

Cuando tenemos un problema de programación, a menudo existen diferentes algoritmos (o "recetas") para solucionarlo. Comparar algoritmos significa analizar cuál de estas "recetas" es más eficiente, especialmente cuando trabajamos con grandes cantidades de datos.

#### 2. **Explicación:**

Imagina que tienes que ordenar una pila gigante de cartas. Podrías usar diferentes métodos:

- **Método 1: Lento pero seguro.** Revisas cada carta y la colocas en su lugar correcto una por una.
- **Método 2: Rápido y eficiente.** Usas un truco más inteligente para ordenar grupos de cartas rápidamente.

Comparar algoritmos es como decidir cuál de estos métodos es mejor, especialmente si la pila de cartas se vuelve ENORME. No solo nos importa que funcione, ¡sino que funcione bien y rápido!

#### 3. **Problemas de probar algoritmos "a lo bruto":**

A veces, podríamos pensar en simplemente escribir el código de cada algoritmo y ver cuál funciona más rápido en nuestra computadora. Pero esto tiene problemas:

- **Mucho trabajo inicial:** ¡Programar y probar varios algoritmos lleva tiempo! Y si al final ninguno es lo suficientemente bueno, ¡es tiempo perdido!
- **Implementación engañosa:** Un algoritmo podría parecer mejor solo porque lo programaste mejor que el otro, ¡no porque el algoritmo en sí sea superior! Es como si un cocinero más hábil hiciera que una receta mediocre parezca deliciosa.
- **Casos de prueba injustos:** Podríamos elegir ejemplos que favorezcan accidentalmente a un algoritmo sobre otro. Imagina probar un coche de carreras solo en una calle de ciudad, ¡no veríamos su verdadero potencial en una autopista!
- **Puede que ninguno sea suficiente:** Incluso el "mejor" algoritmo probado podría ser demasiado lento para lo que necesitas. Y si es así, ¿cómo sabes si existe _algún_ algoritmo que sea lo suficientemente rápido?

#### 4. **La solución: Análisis Asintótico**

Para evitar estos problemas, usamos algo llamado **análisis asintótico**. En lugar de medir el tiempo exacto en una computadora específica, nos fijamos en **cómo crece el tiempo de ejecución de un algoritmo a medida que la cantidad de datos (el "tamaño de la entrada") se hace muy, muy grande.**

**En resumen:** El análisis asintótico nos da una forma más **teórica y general** de comparar algoritmos, ¡sin depender de la computadora que uses o de lo bien que programes!

## B - Análisis Asintótico

#### 1. **Definición:**

El **análisis asintótico** es una técnica para medir la eficiencia de un algoritmo (o programa) enfocándose en cómo se comporta a medida que la **cantidad de datos de entrada se vuelve muy grande**. Es como mirar el "potencial de crecimiento" de un algoritmo, no solo su rendimiento en casos pequeños.

#### 2. **Analogía:**

Imagina que estás viendo crecer dos plantas:

- **Planta A:** Crece muy rápido al principio, pero luego se estanca y apenas crece más.
- **Planta B:** Crece lentamente al principio, pero sigue creciendo de forma constante y, con el tiempo, ¡se hace mucho más alta que la Planta A!

El análisis asintótico se centra en la **Planta B** a largo plazo. No nos importa tanto quién es más alta ahora, sino **quién crecerá más a medida que pase el tiempo (y la entrada de datos se haga más grande).**

#### 3. **¿Qué medimos?**

Normalmente, en el análisis asintótico nos preocupamos por dos cosas principales:

- **Tiempo de ejecución:** ¿Cuánto tiempo tarda el algoritmo en completarse? (Lo más común).
- **Espacio de memoria:** ¿Cuánta memoria necesita el algoritmo para funcionar? (También importante).

#### 4. **¿Por qué es útil?**

- **Independiente de la máquina:** No importa si tienes una computadora súper rápida o una más lenta. El análisis asintótico nos da una idea de la eficiencia del algoritmo en sí, no de la velocidad de tu hardware.
- **Enfoque en lo importante:** Cuando trabajamos con grandes cantidades de datos (¡que es lo común hoy en día!), el análisis asintótico nos dice qué algoritmo realmente escalará mejor y será más eficiente a largo plazo.
- **Decisiones informadas:** Nos ayuda a decidir si un algoritmo es "bueno" o no, y si vale la pena implementarlo, ¡antes de gastar mucho tiempo programando y probando!

#### 5. **Limitaciones:**

El análisis asintótico es una **estimación**. No nos dice cuál algoritmo es "siempre un poquito más rápido" que otro en todos los casos. Pero es una herramienta **poderosa** para decidir si un algoritmo es prometedor o no, especialmente cuando la cantidad de datos crece.

**En resumen:** El análisis asintótico es como usar una lupa para ver cómo se comporta un algoritmo cuando los problemas se hacen GRANDES. Nos ayuda a elegir los algoritmos que realmente "crecen bien" en eficiencia.

## C - Operaciones Básicas y Tamaño de Entrada

#### 1. **Definición de Operación Básica:**

Una **operación básica** es una acción fundamental que realiza un algoritmo, cuyo tiempo de ejecución se considera **constante**, es decir, no cambia significativamente sin importar los valores específicos con los que opera.

#### 2. **Ejemplos de Operaciones Básicas:**

- **Comparar dos números:** Ver si un número es mayor, menor o igual a otro.
- **Sumar dos números:** Calcular la suma de dos valores.
- **Multiplicar dos números:** Calcular el producto de dos valores.
- **Asignar un valor a una variable:** Guardar un valor en la memoria.
- **Acceder a un elemento de un array (o lista):** Obtener el valor que está en una posición específica de un array.

**Importante:** El tiempo que tarda una operación básica **no depende de los _valores_ de los datos**, sino solo de la _operación en sí_.

#### 3. **Definición de Tamaño de Entrada:**

El **tamaño de entrada** es una medida de la cantidad de datos que el algoritmo debe procesar. La forma de medir el "tamaño" depende del problema que estemos resolviendo.

#### 4. **Ejemplos de Tamaño de Entrada:**

- **Ordenar una lista:** El tamaño de entrada es el **número de elementos** en la lista que se va a ordenar.
- **Buscar en un array:** El tamaño de entrada es el **número de elementos** en el array donde se busca.
- **Procesar una cadena de texto:** El tamaño de entrada es la **longitud de la cadena** (número de caracteres).
- **Multiplicar matrices:** El tamaño de entrada podría ser las **dimensiones de las matrices** (número de filas y columnas).

#### 5. **Ejemplo Práctico (Buscar el mayor en un array):**

Considera este código que encuentra el número más grande en un array:

```java
// Java
static int largest(int[] A) {
  int currlarge = 0;
  for (int i=1; i<A.length; i++) {
    if (A[currlarge] < A[i]) {
       currlarge = i;
    }
  }
  return currlarge;
}
```

```cpp
// C++
int largest(int A[], int size) {
  int currlarge = 0;
  for (int i=1; i<size; i++)
    if (A[currlarge] < A[i])
       currlarge = i;
  return currlarge;
}
```

- **Tamaño de entrada:** `A.length` (en Java) o `size` (en C++), que es el número de enteros en el array `A`.
- **Operación básica:** La comparación `A[currlarge] < A[i]`. Asumimos que comparar dos enteros toma un tiempo constante.

**En resumen:** Para analizar un algoritmo, identificamos las **operaciones básicas** (los pasos "pequeños" que se repiten) y el **tamaño de la entrada** (cuántos datos tiene que procesar). Esto nos ayuda a entender cómo se comporta el algoritmo a medida que la entrada crece.

## D - Tiempo de Ejecución T(n)

#### 1. **Definición:**

El **tiempo de ejecución**, representado como **T(n)**, es una función que describe la cantidad de tiempo que tarda un algoritmo en completarse, en función del **tamaño de la entrada (n)**. Siempre asumimos que T(n) es un valor no negativo (el tiempo no puede ser negativo).

#### 2. **¿Cómo se calcula T(n)?**

En el análisis asintótico, no buscamos el tiempo exacto en segundos o milisegundos. En lugar de eso, contamos el **número de operaciones básicas** que realiza el algoritmo en función del tamaño de la entrada 'n'.

#### 3. **Ejemplo 1: Buscar el mayor (de nuevo):**

En el ejemplo anterior de buscar el mayor número en un array, la operación básica es la comparación. En el peor caso, tenemos que comparar cada elemento del array con el mayor actual (excepto el primero). Si el array tiene 'n' elementos, hacemos aproximadamente 'n' comparaciones.

Si llamamos 'c' al tiempo que tarda una comparación, entonces el tiempo total de ejecución T(n) es aproximadamente:

**T(n) = c \* n**

Esto significa que el tiempo de ejecución **crece linealmente** con el tamaño de la entrada 'n'. Si duplicamos el tamaño del array, el tiempo de ejecución también se duplica aproximadamente.

#### 4. **Ejemplo 2: Asignación constante:**

```java
int primerValor = A[0];
```

```cpp
int primerValor = A[0];
```

Aquí, el tamaño de la entrada 'n' (tamaño del array) no importa mucho. La operación básica es copiar el valor del primer elemento del array. Esta operación toma un tiempo constante, digamos 'c1', sin importar cuán grande sea el array.

Entonces, el tiempo de ejecución es:

**T(n) = c1**

Este es un **tiempo de ejecución constante**. El tiempo no cambia con el tamaño de la entrada.

#### 5. **Ejemplo 3: Bucles anidados:**

```java
sum = 0;
for (i=1; i<=n; i++) {
  for (j=1; j<=n; j++) {
    sum++;
  }
}
```

```cpp
sum = 0;
for (i=1; i<=n; i++)
  for (j=1; j<=n; j++)
    sum++;
```

La operación básica aquí es `sum++` (incrementar la variable `sum`). Este bucle interno se ejecuta 'n' veces por cada vez que se ejecuta el bucle externo, que también se ejecuta 'n' veces. En total, la operación `sum++` se ejecuta n \* n = n<sup>2</sup> veces.

Si llamamos 'c2' al tiempo que tarda `sum++`, entonces:

**T(n) = c2 \* n<sup>2</sup>**

Este es un **tiempo de ejecución cuadrático**. El tiempo de ejecución crece mucho más rápido con el tamaño de la entrada que en el caso lineal.

**En resumen:** T(n) nos da una idea de cómo escala el tiempo de ejecución de un algoritmo con el tamaño de la entrada. Identificando las operaciones básicas y cuántas veces se ejecutan, podemos expresar T(n) como una función de 'n'.

## E - Tasas de Crecimiento (Growth Rates)

#### 1. **Definición:**

La **tasa de crecimiento** (growth rate) de un algoritmo describe **cómo aumenta el costo del algoritmo (normalmente el tiempo de ejecución) a medida que el tamaño de la entrada crece.** Es la parte más importante del análisis asintótico porque nos dice qué tan "escalable" es un algoritmo.

#### 2. **Tipos Comunes de Tasas de Crecimiento:**

Aquí tienes las tasas de crecimiento más comunes, ordenadas de más rápido a más lento (a medida que 'n' se hace grande):

- **Factorial: O(n!)** - ¡Crece _extremadamente_ rápido! Muy poco práctico para entradas grandes. Ejemplo: `n!` (n factorial).
- **Exponencial: O(2<sup>n</sup>)** - También crece muy rápido, aunque un poco menos que factorial. Ejemplo: `2<sup>n</sup>`.
- **Cuadrática: O(n<sup>2</sup>)** - Crece más rápido que lineal, pero aún manejable para tamaños de entrada moderados. Ejemplo: `n<sup>2</sup>`.
- **Lineal-Logarítmica: O(n log n)** - Crece un poco más rápido que lineal, pero mucho más lento que cuadrática. Muy común en algoritmos eficientes de ordenamiento y búsqueda. Ejemplo: `n log n`.
- **Lineal: O(n)** - Crece directamente proporcional al tamaño de la entrada. Bastante eficiente. Ejemplo: `n`.
- **Logarítmica: O(log n)** - Crece _muy lentamente_ a medida que 'n' aumenta. ¡Excelente para algoritmos rápidos! Ejemplo: `log n` (normalmente logaritmo base 2 en informática).
- **Constante: O(1)** - No crece en absoluto con el tamaño de la entrada. ¡El más rápido posible en términos de escalabilidad! Ejemplo: `1`.

#### 3. **Gráfica de Tasas de Crecimiento:**

Esta imagen muestra cómo crecen diferentes funciones de tiempo de ejecución a medida que aumenta el tamaño de la entrada 'n'. ¡Mira cómo algunas curvas se disparan mucho más rápido que otras!

[![image](https://opendsa-server.cs.vt.edu/ODSA/Books/Everything/html/_images/growthrates.png)](https://opendsa-server.cs.vt.edu/ODSA/Books/Everything/html/_images/growthrates.png)

[![image](https://opendsa-server.cs.vt.edu/ODSA/Books/Everything/html/_images/growthrates2.png)](https://opendsa-server.cs.vt.edu/ODSA/Books/Everything/html/_images/growthrates2.png)

**Observa:**

- Las líneas rectas (10n, 20n) representan crecimiento **lineal**.
- La curva (2n<sup>2</sup>) representa crecimiento **cuadrático**.
- Las curvas que se disparan hacia arriba (2<sup>n</sup>, n!) representan crecimiento **exponencial**.
- La curva (5n log<sub>2</sub>n) está entre lineal y cuadrática, es **lineal-logarítmica**.

#### 4. **Tabla de Costos para Diferentes Tasas de Crecimiento:**

Esta tabla te da una idea más concreta de cómo los diferentes tamaños de entrada afectan el tiempo de ejecución para diferentes tasas de crecimiento. ¡Fíjate en los números ENORMES para tasas de crecimiento rápidas como n! y 2<sup>n</sup> incluso para entradas relativamente pequeñas!

**Tabla 8.3.1: Costos para tasas de crecimiento representativas.**

| n     | log log n | log n | n    | n log n  | n<sup>2</sup> | n<sup>3</sup> | 2<sup>n</sup>       | n!               |
| :---- | :-------- | :---- | :--- | :------- | :------------ | :------------ | :------------------ | :--------------- |
| 16    | 2         | 4     | 16   | 64       | 256           | 4096          | 65,536              | 2.09e+13         |
| 256   | 3         | 8     | 256  | 2,048    | 65,536        | 16,777,216    | 1.15e+77            | 8.57e+506        |
| 1,024 | ≈3.3      | 10    | 1024 | 10,240   | 1,048,576     | 1.07e+9       | 1.79e+308           | ¡MUY GRANDE!     |
| 64K   | ≈4.3      | 16    | 64K  | 1.05e+6  | 4.29e+9       | 2.81e+14      | ¡INFINITO PRÁCTICO! | ¡AÚN MÁS GRANDE! |
| 1M    | ≈4.9      | 20    | 1M   | 2.09e+7  | 1.10e+12      | 1.00e+18      | ¡INFINITO PRÁCTICO! | ¡AÚN MÁS GRANDE! |
| 1G    | -         | 30    | 1G   | 3.00e+10 | 1.15e+18      | 1.20e+27      | ¡INFINITO PRÁCTICO! | ¡AÚN MÁS GRANDE! |

_(Nota: 64K = 64 _ 1024, 1M = 1 millón, 1G = 1 giga = 1 billón)\*

**Conclusión clave:** ¡La tasa de crecimiento es LO QUE MÁS IMPORTA! Un algoritmo con una tasa de crecimiento lenta (como logarítmica o lineal) será mucho más eficiente para entradas grandes que uno con una tasa de crecimiento rápida (como cuadrática o exponencial), ¡incluso si el algoritmo "rápido" es un poco más rápido para entradas pequeñas!

#### 5. **Factores que NO importan tanto en el análisis asintótico:**

Cuando hablamos de tasas de crecimiento, **ignoramos** los factores constantes y los términos de menor orden en la función T(n). Por ejemplo:

- Si T(n) = 10n + 5, decimos que la tasa de crecimiento es **O(n)** (lineal), ignoramos el '10' y el '+5'.
- Si T(n) = 0.5n<sup>2</sup> + 20n + 100, decimos que la tasa de crecimiento es **O(n<sup>2</sup>)** (cuadrática), ignoramos el '0.5', el '20n' y el '100'.

**¿Por qué ignoramos estas cosas?** Porque para entradas **MUY GRANDES**, la tasa de crecimiento (el término de mayor orden) es lo que realmente domina el tiempo de ejecución. Los factores constantes y los términos más pequeños se vuelven insignificantes en comparación.

**En resumen:** Las tasas de crecimiento nos dan una forma de clasificar los algoritmos según su eficiencia a largo plazo. Conocer las tasas de crecimiento comunes y cómo compararlas es fundamental para elegir buenos algoritmos, ¡especialmente cuando trabajas con grandes cantidades de datos!
