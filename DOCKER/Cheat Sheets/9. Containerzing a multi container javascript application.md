## A - Red de Puente Personalizada en Docker

#### 1. **Definición:**

Una red de puente personalizada en Docker es como una carretera privada que creas para que tus contenedores se comuniquen entre sí de forma segura y eficiente. En lugar de usar la red predeterminada de Docker, tú defines una nueva red, dándole un nombre y controlando cómo se conectan los contenedores a ella. Esto es crucial para aplicaciones con múltiples contenedores que necesitan hablar entre ellos, como una API y una base de datos.

#### 2. **Ejemplo:**

```bash
docker network create notes-api-network
```

**Explicación del ejemplo:**
Este comando crea una red de puente personalizada llamada `notes-api-network`. Ahora, cualquier contenedor que conectes a esta red podrá comunicarse con otros contenedores en la misma red usando sus nombres de contenedor como si fueran nombres de host.

#### 3. **Notas o advertencias:**

- Usar redes de puente personalizadas es una buena práctica para aplicaciones multi-contenedor.
- Permite el descubrimiento de servicios por nombre de contenedor, simplificando la configuración.
- Aísla el tráfico de red de tu aplicación del resto de la red Docker predeterminada, mejorando la seguridad y organización.

---

## B - Ejecutando el Servidor de Base de Datos (PostgreSQL)

#### 1. **Definición:**

Para que tu aplicación funcione, a menudo necesitas una base de datos. Docker facilita esto permitiéndote ejecutar un servidor de base de datos, como PostgreSQL, dentro de un contenedor. Necesitas configurar ciertas cosas como contraseñas y nombres de bases de datos usando variables de entorno, y decirle a Docker que "publique" el puerto de la base de datos para que la aplicación pueda acceder a ella.

#### 2. **Ejemplo:**

```bash
docker container run \
    --detach \
    --name=notes-db \
    --env POSTGRES_DB=notesdb \
    --env POSTGRES_PASSWORD=secret \
    --network=notes-api-network \
    postgres:12
```

**Explicación del ejemplo:**

- `docker container run`: Este comando inicia un nuevo contenedor.
- `--detach`: Ejecuta el contenedor en segundo plano.
- `--name=notes-db`: Le da el nombre "notes-db" a este contenedor para que puedas referirte a él fácilmente.
- `--env POSTGRES_DB=notesdb`: Define la variable de entorno `POSTGRES_DB` con el valor `notesdb`. PostgreSQL usará esto para nombrar la base de datos por defecto.
- `--env POSTGRES_PASSWORD=secret`: Define la contraseña para el usuario `postgres` de PostgreSQL. ¡En la vida real, usa contraseñas más seguras!
- `--network=notes-api-network`: Conecta este contenedor a la red que creamos antes, `notes-api-network`.
- `postgres:12`: Usa la imagen oficial de PostgreSQL versión 12 desde Docker Hub.

#### 3. **Notas o advertencias:**

- Siempre revisa la documentación de la imagen de Docker que estés usando (como `postgres` en Docker Hub) para entender qué variables de entorno son necesarias y cómo configurarlas.
- Publicar puertos (`-p` o `--publish`) es necesario si quieres acceder a la base de datos desde fuera de la red Docker, pero en este caso, como la API y la base de datos están en la misma red, no necesitamos publicar el puerto para la comunicación entre contenedores.

---

## C - Trabajando con Volúmenes Nombrados

#### 1. **Definición:**

Imagina que la información de tu base de datos es como documentos importantes. Si solo guardas esos documentos dentro del contenedor, y el contenedor desaparece, ¡adiós documentos! Los volúmenes nombrados son como carpetas especiales fuera de los contenedores, pero gestionadas por Docker. Puedes guardar datos importantes en estos volúmenes, y aunque el contenedor se borre, los datos permanecen seguros y puedes reutilizarlos con otro contenedor.

#### 2. **Ejemplo:**

Primero, crea un volumen nombrado:

```bash
docker volume create notes-db-data
```

Luego, al ejecutar el contenedor de la base de datos, usa este volumen:

```bash
docker container run \
    --detach \
    --volume notes-db-data:/var/lib/postgresql/data \
    --name=notes-db \
    --env POSTGRES_DB=notesdb \
    --env POSTGRES_PASSWORD=secret \
    --network=notes-api-network \
    postgres:12
```

**Explicación del ejemplo:**

- `docker volume create notes-db-data`: Crea un volumen nombrado llamado `notes-db-data`.
- `--volume notes-db-data:/var/lib/postgresql/data` (o `-v notes-db-data:/var/lib/postgresql/data`): Esto "monta" el volumen nombrado `notes-db-data` en la ruta `/var/lib/postgresql/data` dentro del contenedor. Esta ruta es donde PostgreSQL guarda sus datos por defecto. Ahora, los datos de la base de datos se guardarán en el volumen nombrado.

#### 3. **Notas o advertencias:**

- Los volúmenes nombrados son preferibles a los volúmenes anónimos porque son más fáciles de gestionar y reutilizar. Puedes referirte a ellos por su nombre.
- A diferencia de los "bind mounts" (donde montas una carpeta de tu sistema directamente en el contenedor), los volúmenes nombrados son gestionados completamente por Docker, lo que a menudo es más seguro y portable.

---

## D - Accediendo a los Logs de un Contenedor

#### 1. **Definición:**

Los "logs" son como el diario de un contenedor. Registran todo lo que sucede dentro del contenedor: errores, mensajes informativos, etc. Ver los logs es crucial para entender qué está pasando dentro de tu contenedor, especialmente si algo no funciona como esperas.

#### 2. **Ejemplo:**

```bash
docker container logs notes-db
```

**Explicación del ejemplo:**

- `docker container logs notes-db`: Este comando muestra los logs del contenedor llamado `notes-db`. Verás en la consola la salida que el proceso principal dentro del contenedor (en este caso, PostgreSQL) está generando.

#### 3. **Notas o advertencias:**

- Para ver los logs en tiempo real, como si estuvieras viendo una transmisión en vivo, puedes usar la opción `-f` o `--follow`: `docker container logs -f notes-db`. Esto es útil para depurar problemas mientras ocurren.
- Los logs son muy útiles para diagnosticar problemas, verificar que la aplicación se está iniciando correctamente, y monitorizar su funcionamiento.

---

## E - Conectando un Contenedor a una Red (Si te lo perdiste antes)

#### 1. **Definición:**

Si por alguna razón olvidaste conectar un contenedor a una red al crearlo, o si quieres añadir un contenedor a una red existente después de que ya está corriendo, puedes hacerlo con el comando `docker network connect`.

#### 2. **Ejemplo:**

```bash
docker network connect notes-api-network notes-db
```

**Explicación del ejemplo:**

- `docker network connect notes-api-network notes-db`: Este comando conecta el contenedor `notes-db` a la red `notes-api-network`. Después de ejecutar esto, si el contenedor no estaba ya en la red, ahora podrá comunicarse con otros contenedores en `notes-api-network`.

#### 3. **Notas o advertencias:**

- Puedes verificar a qué redes está conectado un contenedor inspeccionando el contenedor con `docker container inspect notes-db` y buscando en la sección "NetworkSettings".
- También puedes verificar qué contenedores están conectados a una red con `docker network inspect notes-api-network` y mirando en la sección "Containers".

---

## F - Escribiendo el Dockerfile

#### 1. **Definición:**

Un `Dockerfile` es como una receta para construir una imagen de Docker. Es un archivo de texto que contiene instrucciones paso a paso sobre cómo crear tu imagen, incluyendo desde qué imagen base empezar, qué software instalar, qué archivos copiar, y qué comando ejecutar cuando el contenedor se inicie. El ejemplo muestra un `Dockerfile` "multi-stage", que es una forma eficiente de construir imágenes más pequeñas y seguras.

#### 2. **Ejemplo:**

```dockerfile
# stage one
FROM node:lts-alpine as builder

# install dependencies for node-gyp
RUN apk add --no-cache python make g++

WORKDIR /app

COPY ./package.json .
RUN npm install --only=prod

# stage two
FROM node:lts-alpine

EXPOSE 3000
ENV NODE_ENV=production

USER node
RUN mkdir -p /home/node/app
WORKDIR /home/node/app

COPY . .
COPY --from=builder /app/node_modules  /home/node/app/node_modules

CMD [ "node", "bin/www" ]
```

**Explicación del ejemplo:**

- **Stage One (builder):**
  - `FROM node:lts-alpine as builder`: Empieza con una imagen base de Node.js (versión LTS en Alpine Linux) y la nombra "builder".
  - `RUN apk add --no-cache python make g++`: Instala herramientas necesarias para compilar módulos de Node.js (para `node-gyp`).
  - `WORKDIR /app`: Establece el directorio de trabajo dentro de la imagen a `/app`.
  - `COPY ./package.json .`: Copia el archivo `package.json` al directorio de trabajo.
  - `RUN npm install --only=prod`: Instala solo las dependencias de producción de Node.js.
- **Stage Two (final image):**
  - `FROM node:lts-alpine`: Empieza de nuevo con otra imagen base de Node.js (Alpine). Esta será la imagen final.
  - `EXPOSE 3000`: Indica que el contenedor expondrá el puerto 3000.
  - `ENV NODE_ENV=production`: Define la variable de entorno `NODE_ENV` como `production`. Esto es importante para que la API se ejecute en modo producción.
  - `USER node`: Cambia el usuario a `node` para mayor seguridad (ejecuta la aplicación como un usuario no root).
  - `RUN mkdir -p /home/node/app`: Crea el directorio `/home/node/app`.
  - `WORKDIR /home/node/app`: Establece el directorio de trabajo a `/home/node/app`.
  - `COPY . .`: Copia todos los archivos del proyecto al directorio de trabajo.
  - `COPY --from=builder /app/node_modules  /home/node/app/node_modules`: Copia solo la carpeta `node_modules` (con las dependencias ya instaladas en el stage "builder") desde el stage "builder" a la imagen final. ¡Esto hace que la imagen final sea mucho más pequeña porque no incluye las herramientas de compilación!
  - `CMD [ "node", "bin/www" ]`: Define el comando que se ejecutará cuando el contenedor se inicie: ejecutar el archivo `bin/www` con Node.js (que suele ser el punto de entrada de aplicaciones Express.js).

#### 3. **Notas o advertencias:**

- Los Dockerfiles multi-stage son una técnica avanzada pero muy útil para optimizar el tamaño y la seguridad de las imágenes de Docker.
- La primera etapa ("builder") se usa para construir y preparar todo lo necesario (como instalar dependencias), y la segunda etapa (la final) solo contiene lo mínimo necesario para ejecutar la aplicación.
- `Alpine` es una distribución de Linux muy ligera, lo que ayuda a que las imágenes basadas en ella sean más pequeñas.

---

## G - Construyendo la Imagen Docker

#### 1. **Definición:**

Una vez que tienes tu `Dockerfile` escrito, necesitas "construir" la imagen de Docker a partir de él. Este proceso lee las instrucciones en el `Dockerfile` y crea una imagen que puedes usar para ejecutar contenedores.

#### 2. **Ejemplo:**

```bash
docker image build --tag notes-api .
```

**Explicación del ejemplo:**

- `docker image build`: Este comando inicia el proceso de construcción de la imagen.
- `--tag notes-api` (o `-t notes-api`): Le da el nombre "notes-api" a la imagen que se va a construir. Puedes usar este nombre para referirte a la imagen después.
- `.`: Indica que el `Dockerfile` está en el directorio actual. Docker buscará un archivo llamado `Dockerfile` en este directorio (o puedes especificar una ruta diferente con la opción `-f`).

#### 3. **Notas o advertencias:**

- Es una buena práctica etiquetar tus imágenes con nombres descriptivos y, opcionalmente, versiones (ej., `notes-api:v1.0`).
- Asegúrate de estar en el directorio correcto (donde está el `Dockerfile`) cuando ejecutes el comando `docker image build`.
- La primera vez que construyes una imagen, Docker descargará las imágenes base y ejecutará todos los pasos, lo que puede llevar un tiempo. Las construcciones posteriores serán más rápidas gracias al sistema de caché de Docker.

---

## H - Ejecutando el Contenedor de la API

#### 1. **Definición:**

Después de construir la imagen de tu API, el siguiente paso es ejecutar un contenedor basado en esa imagen. Al igual que con el contenedor de la base de datos, necesitas configurarlo, en este caso, principalmente proporcionando variables de entorno para que la API sepa cómo conectarse a la base de datos.

#### 2. **Ejemplo:**

```bash
docker container run \
    --detach \
    --name=notes-api \
    --env DB_HOST=notes-db \
    --env DB_DATABASE=notesdb \
    --env DB_PASSWORD=secret \
    --publish=3000:3000 \
    --network=notes-api-network \
    notes-api
```

**Explicación del ejemplo:**

- `docker container run`: Inicia un nuevo contenedor.
- `--detach`: Ejecuta el contenedor en segundo plano.
- `--name=notes-api`: Le da el nombre "notes-api" al contenedor.
- `--env DB_HOST=notes-db`: Define la variable de entorno `DB_HOST` como `notes-db`. ¡Aquí está la magia! Como ambos contenedores (API y base de datos) están en la misma red (`notes-api-network`), la API puede usar el nombre del contenedor de la base de datos (`notes-db`) como si fuera el nombre de host para conectarse a ella. Docker resuelve este nombre internamente.
- `--env DB_DATABASE=notesdb`: Define el nombre de la base de datos que la API debe usar (configurado previamente en el contenedor de la base de datos).
- `--env DB_PASSWORD=secret`: Define la contraseña para acceder a la base de datos.
- `--publish=3000:3000` (o `-p 3000:3000`): Publica el puerto 3000 del contenedor en el puerto 3000 de tu máquina local. Esto te permite acceder a la API desde tu navegador en `http://127.0.0.1:3000/`.
- `--network=notes-api-network`: Conecta el contenedor a la red `notes-api-network`.
- `notes-api`: Usa la imagen llamada `notes-api` que construimos antes.

#### 3. **Notas o advertencias:**

- Las variables de entorno son una forma común y segura de pasar configuración a tus aplicaciones en contenedores. Evitan tener que "hardcodear" información sensible como contraseñas dentro de la imagen.
- Asegúrate de que los nombres de las variables de entorno (`DB_HOST`, `DB_DATABASE`, `DB_PASSWORD`) coincidan con lo que tu aplicación API espera leer para configurar la conexión a la base de datos.

---

## I - Ejecutando Comandos en un Contenedor en Ejecución

#### 1. **Definición:**

A veces necesitas ejecutar comandos _dentro_ de un contenedor que ya está corriendo. Por ejemplo, para ejecutar migraciones de base de datos, inspeccionar archivos, o iniciar un shell para depurar. `docker container exec` te permite hacer precisamente eso.

#### 2. **Ejemplo:**

Para ejecutar migraciones de base de datos en el contenedor `notes-api`:

```bash
docker container exec notes-api npm run db:migrate
```

Para iniciar un shell interactivo dentro del contenedor `notes-api`:

```bash
docker container exec -it notes-api sh
```

**Explicación del ejemplo:**

- `docker container exec notes-api npm run db:migrate`: Ejecuta el comando `npm run db:migrate` dentro del contenedor `notes-api`. Esto es útil para tareas como migraciones de base de datos o cualquier script que necesites ejecutar en el contexto de la aplicación dentro del contenedor.
- `docker container exec -it notes-api sh`: Ejecuta el comando `sh` (shell) dentro del contenedor `notes-api`. Las opciones `-it` hacen que la sesión sea interactiva (`-i`) y asignan un pseudo-TTY (`-t`), lo que te da un shell dentro del contenedor. Puedes escribir comandos directamente en este shell.

#### 3. **Notas o advertencias:**

- Usa `-it` cuando quieras una sesión interactiva, como un shell. Si solo quieres ejecutar un comando no interactivo y ver su salida, no necesitas `-it`.
- El shell que se inicia dentro del contenedor (`sh`, `bash`, etc.) depende de lo que esté disponible en la imagen del contenedor. En imágenes Alpine, `sh` suele ser `ash`, un shell ligero.

---

## J - Escribiendo Scripts de Gestión

#### 1. **Definición:**

Gestionar aplicaciones multi-contenedor con Docker puede involucrar muchos comandos. Para simplificar esto, es muy útil crear scripts de gestión. Estos scripts son como "botones grandes" que ejecutan secuencias de comandos Docker por ti, como iniciar todos los contenedores, detenerlos, reconstruir la aplicación, etc. El ejemplo menciona scripts shell (`.sh`) y un `Makefile`, que son herramientas comunes para automatizar tareas en entornos Linux/Unix.

#### 2. **Ejemplo:**

El texto menciona los siguientes scripts en el directorio `notes-api`:

- `boot.sh`: Para iniciar contenedores que ya existen.
- `build.sh`: Para crear y ejecutar contenedores, creando imágenes, volúmenes y redes si es necesario.
- `destroy.sh`: Para eliminar todos los contenedores, volúmenes y redes del proyecto.
- `stop.sh`: Para detener todos los contenedores en ejecución.
- `Makefile`: Un archivo de configuración para la herramienta `make`, que permite definir "targets" (objetivos) como `start`, `stop`, `build`, `destroy` que ejecutan los scripts shell correspondientes.

Para ejecutar un target de `Makefile`, por ejemplo `destroy`, usarías el comando:

```bash
make destroy
```

**Explicación del ejemplo:**

- Estos scripts y el `Makefile` son ejemplos de cómo puedes automatizar la gestión de tu aplicación Docker. En lugar de recordar y escribir comandos Docker largos y repetitivos, puedes ejecutar un simple comando como `make build` o `./boot.sh`.
- `Makefile` es especialmente útil porque organiza los comandos en "targets" con nombres, lo que hace que la gestión sea más clara y fácil de usar.

#### 3. **Notas o advertencias:**

- Crear scripts de gestión es una excelente práctica para cualquier proyecto Docker, especialmente para aplicaciones multi-contenedor. Ahorra tiempo, reduce errores y hace que la gestión del proyecto sea más consistente.
- Los scripts shell son útiles para tareas sencillas. Para proyectos más complejos, herramientas como `docker-compose` o incluso orquestadores de contenedores como Kubernetes pueden ser más apropiados.
- Asegúrate de dar permisos de ejecución a los scripts shell (`chmod +x script.sh`) para poder ejecutarlos directamente.
