## A - Limitando Peticiones: ¡Ponle Freno al Caos!

#### 1. **Definicion:**

**Limitar peticiones** (o _rate limiting_ en inglés) es como poner un portero en la puerta de tu aplicación. Imagina que tienes una fiesta en casa (tu aplicación) y no quieres que entre demasiada gente de golpe porque se llenaría demasiado y se volvería un caos. El _rate limiting_ hace justo eso: **controla cuántas peticiones (invitados) puede recibir tu aplicación en un cierto tiempo**, evitando que se sature y se caiga por exceso de trabajo.

#### 2. **Ejemplo:**

Piensa en un restaurante muy popular. Si no controlaran la entrada, todo el mundo querría entrar a la vez, la cocina no daría abasto, los camareros se estresarían y la experiencia para todos sería terrible. El restaurante usa un sistema de reservas o listas de espera para **limitar el ritmo al que entra la gente**, asegurándose de que pueden atender a todos bien y sin colapsar. ¡El _rate limiting_ es la versión digital de esto para tu aplicación!

#### 3. **Notas o advertencias:**

- Limitar peticiones es **esencial para la seguridad y la estabilidad** de tu aplicación, especialmente si esperas mucho tráfico o si quieres protegerte de ataques maliciosos.
- No solo se trata de evitar que tu servidor se caiga, sino también de **protegerte de ataques de fuerza bruta** (intentos masivos de adivinar contraseñas) o ataques DDoS (intentos de tumbar tu servicio con una avalancha de peticiones).
- Hay varias formas de implementar _rate limiting_, desde usar herramientas especializadas como **balanceadores de carga** hasta usar **middleware** dentro de tu propia aplicación. ¡Vamos a ver algunas!

## B - Formas de Limitar Peticiones: ¡Elige tu Portero!

#### 1. **Definicion:**

Hay diferentes maneras de ponerle un límite a las peticiones que recibe tu aplicación. Puedes usar herramientas que están "por delante" de tu aplicación, como un **balanceador de carga**, o puedes usar librerías o **middleware** dentro de tu código. Cada opción tiene sus ventajas y es útil en diferentes situaciones.

#### 2. **Ejemplo:**

**B.1 - Balanceador de Carga (Nginx): El Portero Robusto**

- **Definición:** Un **balanceador de carga** como Nginx es como un portero muy experimentado que se pone delante de tu edificio (servidor). Puede distribuir el tráfico entre varios servidores si tienes muchos, y también puede **limitar el número de peticiones** que llegan a tu aplicación.

- **Notas:** Usar un balanceador de carga es una **solución muy potente y escalable**, ideal para aplicaciones grandes o que esperan mucho tráfico. Nginx es muy bueno en esto y se usa muchísimo en internet.

**B.2 - Middleware/Librerías: El Portero Interno**

- **Definición:** El **middleware** o las librerías de _rate limiting_ son como porteros que pones **dentro de tu propia aplicación**. Son piezas de código que se encargan de revisar cada petición que llega y decidir si la dejan pasar o no, basándose en reglas que tú defines.

- **Ejemplos:**

  - `rate-limiter-flexible`: Una librería muy flexible para Node.js que te permite crear reglas de _rate limiting_ muy personalizadas.
  - `express-rate-limit`: Un **middleware** específico para aplicaciones hechas con Express.js (un framework muy popular para Node.js). Es muy fácil de usar y configurar.

- **Notas:** Usar middleware o librerías es una **forma más sencilla y rápida** de implementar _rate limiting_, especialmente para aplicaciones más pequeñas o cuando quieres un control más fino sobre las reglas de limitación.

## C - Ejemplo con `rate-limiter-flexible`: ¡Código al Rescate!

#### 1. **Definicion:**

Vamos a ver un ejemplo de cómo usar la librería `rate-limiter-flexible` en una aplicación Node.js sencilla. Esta librería es muy potente y te da mucho control sobre cómo quieres limitar las peticiones.

#### 2. **Ejemplo:**

```javascript
const http = require("http");
const IoRedis = require("ioredis");
const { RateLimiterRedis } = require("rate-limiter-flexible");

const redisClient = new IoRedis({ enableOfflineQueue: false });

// Máximo 20 peticiones por segundo
const rateLimiter = new RateLimiterRedis({
  storeClient: redisClient,
  points: 20, // Máximo 20 peticiones...
  duration: 1, // ...por cada segundo
  blockDuration: 2, // Bloquea durante 2 segundos si se superan las 20 peticiones en 1 segundo
});

http
  .createServer(async (req, res) => {
    try {
      const rateLimiterRes = await rateLimiter.consume(
        req.socket.remoteAddress
      );
      // Aquí iría la lógica de tu aplicación

      res.writeHead(200); // Todo OK
      res.end();
    } catch {
      res.writeHead(429); // Código de error "Demasiadas peticiones"
      res.end("Too Many Requests"); // Mensaje para el usuario
    }
  })
  .listen(3000);
```

**Explicación del ejemplo:**

- **`IoRedis` y `RateLimiterRedis`**: Importamos las librerías necesarias. `IoRedis` es un cliente de Redis (una base de datos muy rápida que se usa para guardar información temporalmente) y `RateLimiterRedis` es la clase principal de `rate-limiter-flexible` que usa Redis para llevar la cuenta de las peticiones.
- **`rateLimiter`**: Creamos una instancia de `RateLimiterRedis` y le decimos:
  - `storeClient: redisClient`: Que use Redis para guardar la información de las peticiones.
  - `points: 20`, `duration: 1`: Permite un máximo de **20 peticiones por segundo**.
  - `blockDuration: 2`: Si alguien supera las 20 peticiones en un segundo, **bloquéalo durante 2 segundos**.
- **`http.createServer(...)`**: Creamos un servidor HTTP normal.
- **`rateLimiter.consume(req.socket.remoteAddress)`**: En cada petición, llamamos a `rateLimiter.consume(...)`. Esto hace dos cosas:
  1.  **Comprueba si se ha superado el límite** de peticiones para la IP que hace la petición (`req.socket.remoteAddress`).
  2.  **Resta un "punto"** al contador de peticiones para esa IP.
  - Si **no se ha superado el límite**, `consume()` devuelve un objeto con información sobre el límite restante (que guardamos en `rateLimiterRes`) y el código sigue ejecutándose normalmente (la lógica de tu aplicación).
  - Si **se ha superado el límite**, `consume()` lanza un error (por eso usamos `try...catch`).
- **`catch`**: Si `consume()` lanza un error, significa que se han hecho demasiadas peticiones. En ese caso, enviamos una respuesta con código de error `429 Too Many Requests` y un mensaje para el usuario.

#### 3. **Notas o advertencias:**

- Este ejemplo usa **Redis** para guardar la información de las peticiones. Necesitarás tener Redis instalado y funcionando para que este código funcione.
- `rate-limiter-flexible` es **muy configurable**. Puedes definir límites diferentes para diferentes rutas, usuarios, etc. ¡Mira la documentación para ver todas las opciones!
- Fíjate en cómo usamos `req.socket.remoteAddress` para identificar al cliente que hace la petición. Esto funciona bien en muchos casos, pero si estás detrás de un proxy, puede que necesites configurarlo de otra manera para obtener la IP real del cliente.

## D - Ejemplo con `express-rate-limit`: ¡Fácil para Express!

#### 1. **Definicion:**

Si estás usando Express.js, el middleware `express-rate-limit` te lo pone aún más fácil para añadir _rate limiting_ a tus rutas. ¡Vamos a verlo!

#### 2. **Ejemplo:**

```javascript
const express = require("express");
const RateLimit = require("express-rate-limit");
const app = express();

// Importante si estás detrás de un proxy para que req.ip tenga la IP real del cliente
app.enable("trust proxy");

const apiLimiter = new RateLimit({
  windowMs: 15 * 60 * 1000, // 15 minutos
  max: 100, // Máximo 100 peticiones en 15 minutos
  message:
    "Demasiadas peticiones desde esta IP, por favor intenta de nuevo en 15 minutos",
});

// Aplica el limitador solo a las rutas que empiecen por /user/
app.use("/user/", apiLimiter);

app.get("/user/profile", (req, res) => {
  res.send("Perfil de usuario");
});

app.get("/user/settings", (req, res) => {
  res.send("Configuración de usuario");
});

app.get("/", (req, res) => {
  res.send("Página principal sin límite"); // Esta ruta no tiene límite
});

app.listen(3000);
```

**Explicación del ejemplo:**

- **`RateLimit = require('express-rate-limit')`**: Importamos el middleware `express-rate-limit`.
- **`app.enable('trust proxy')`**: **¡Muy importante si estás detrás de un proxy!** Esto le dice a Express que confíe en los headers que le envía el proxy para obtener la IP real del cliente (`req.ip`). Si no haces esto y estás detrás de un proxy, todas las peticiones parecerán venir de la misma IP del proxy y el _rate limiting_ no funcionará bien.
- **`apiLimiter = new RateLimit(...)`**: Creamos una instancia de `RateLimit` y le decimos:
  - `windowMs: 15 * 60 * 1000`: El "ventana de tiempo" para el límite es de **15 minutos**.
  - `max: 100`: Permite un máximo de **100 peticiones en 15 minutos**.
  - `message: ...`: Un mensaje personalizado que se enviará al cliente si supera el límite.
- **`app.use('/user/', apiLimiter)`**: **Aplicamos el middleware `apiLimiter` solo a las rutas que empiecen por `/user/`**. Esto significa que las rutas `/user/profile` y `/user/settings` tendrán _rate limiting_, pero la ruta `/` (página principal) no.
- **Rutas de ejemplo**: Definimos algunas rutas de ejemplo para `/user/profile`, `/user/settings` y `/`.

#### 3. **Notas o advertencias:**

- `express-rate-limit` es **muy fácil de usar** y configurar en aplicaciones Express.js.
- Puedes aplicar el _rate limiting_ **a rutas específicas** (como en este ejemplo con `/user/`) o a **toda tu aplicación**.
- Al igual que con `rate-limiter-flexible`, `express-rate-limit` también usa **memorias internas o bases de datos** (como Redis o Memcached) para guardar la información de las peticiones, dependiendo de la configuración. Por defecto, usa la memoria, pero para producción es mejor usar una base de datos para que el límite se mantenga incluso si reinicias tu servidor.

## E - ¿Por Qué Limitar Peticiones? ¡Beneficios Claros!

#### 1. **Definicion:**

Limitar las peticiones no es solo una buena práctica, ¡es **fundamental para la seguridad y el buen funcionamiento** de tu aplicación! Te protege de muchos problemas y te da tranquilidad.

#### 2. **Ejemplo:**

Como dice el blog de NGINX:

> "La limitación de velocidad puede utilizarse con fines de seguridad, por ejemplo, para ralentizar los ataques de fuerza bruta para adivinar contraseñas. Puede ayudar a proteger contra ataques DDoS limitando la tasa de peticiones entrantes a un valor típico para usuarios reales y (con registro) identificar las URLs objetivo. Más generalmente, se utiliza para proteger los servidores de aplicaciones _upstream_ de ser sobrecargados por demasiadas peticiones de usuario al mismo tiempo."

**Explicación del ejemplo:**

El blog de Nginx lo explica muy bien: el _rate limiting_ sirve para:

- **Seguridad:** Ralentiza o detiene ataques de fuerza bruta (adivinación de contraseñas) y ayuda a proteger contra ataques DDoS.
- **Estabilidad:** Evita que tu servidor se sature y se caiga por exceso de peticiones, asegurando que tu aplicación siga funcionando para todos los usuarios.
- **Experiencia de usuario:** Al mantener tu aplicación estable y rápida, mejoras la experiencia de todos los usuarios, incluso en momentos de mucho tráfico.

#### 3. **Notas o advertencias:**

- Implementar _rate limiting_ es una **medida de seguridad proactiva**. Es mejor prevenir problemas antes de que ocurran.
- No esperes a sufrir un ataque o una caída por sobrecarga para empezar a pensar en _rate limiting_. **¡Añádelo a tus aplicaciones desde el principio!**
- Combinar _rate limiting_ con otras medidas de seguridad (como linters de seguridad, validación de entradas, etc.) te dará una protección mucho más completa.
