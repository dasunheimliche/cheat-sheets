## A - NGINX como Balanceador de Carga

#### 1. **Definición:**

NGINX, gracias a su diseño de proxy inverso, puede actuar como un **balanceador de carga**. Imagínate que tienes varios servidores haciendo el mismo trabajo. Un balanceador de carga es como un director de tráfico que decide a qué servidor enviar cada petición. Así, el trabajo se reparte y ningún servidor se sobrecarga.

#### 2. **Ejemplo:**

Imagina un restaurante (tu aplicación) con varios cocineros (servidores). Si solo hay un cocinero, se saturará rápido. Un balanceador de carga sería como el jefe de cocina que reparte los pedidos entre los cocineros disponibles para que todos trabajen de forma eficiente y nadie se sature.

**Explicación del ejemplo:**
En este ejemplo, NGINX es el jefe de cocina y los servidores Node.js son los cocineros. NGINX decide a qué servidor enviar cada petición para que la carga se distribuya de manera uniforme.

#### 3. **Notas o advertencias:**

- En proyectos grandes, el balanceo de carga es crucial para mantener la aplicación rápida y disponible.
- Este cheat sheet te dará una base sólida, pero el balanceo de carga puede ser más complejo en escenarios reales.

## B - Preparando el Demo de Balanceo de Carga

Para que veas cómo funciona esto en la práctica, vamos a montar un pequeño demo. Necesitarás tener Node.js y PM2 instalados.

#### 1. **Node.js:**

**Definición:**
Node.js es un entorno para ejecutar código JavaScript fuera del navegador. Lo usaremos para crear servidores web muy sencillos para nuestro demo.

**Instalación:**
Si no lo tienes, puedes instalarlo siguiendo este [link](https://github.com/nodesource/distributions#debinstall).

#### 2. **PM2:**

**Definición:**
PM2 es un gestor de procesos para Node.js. Nos ayudará a mantener nuestros servidores Node.js funcionando en segundo plano (daemonizarlos) y a gestionarlos fácilmente.

**Instalación:**
Abre tu terminal y ejecuta:

```bash
sudo npm install -g pm2
```

**Explicación:**
`npm` es el gestor de paquetes de Node.js. Con este comando, instalamos PM2 de forma global (`-g`), para que esté disponible en todo el sistema. `sudo` es necesario para instalarlo globalmente.

#### 3. **Servidores Demo (Node.js):**

**Definición:**
Para este demo, usaremos tres servidores Node.js muy simples. Cada uno responderá con un mensaje diferente para que veamos cuál de ellos responde a cada petición.

**Código:**
Ya tienes el código de estos servidores en el repositorio que mencionaba el texto, en la carpeta `/srv/nginx-handbook-projects/load-balancer-demo/`. Son archivos llamados `server-1.js`, `server-2.js` y `server-3.js`.

#### 4. **Arrancando los Servidores Demo con PM2:**

**Comandos:**
Abre tu terminal y ejecuta estos comandos uno por uno:

```bash
pm2 start /srv/nginx-handbook-projects/load-balancer-demo/server-1.js
pm2 start /srv/nginx-handbook-projects/load-balancer-demo/server-2.js
pm2 start /srv/nginx-handbook-projects/load-balancer-demo/server-3.js
```

**Verificando que los servidores están funcionando:**
Para ver si todo ha ido bien, ejecuta:

```bash
pm2 list
```

Deberías ver algo como esto:

```
# ┌────┬────────────────────┬──────────┬──────┬───────────┬──────────┬──────────┐
# │ id │ name               │ mode     │ ↺    │ status    │ cpu      │ memory   │
# ├────┼────────────────────┬──────────┼──────┼───────────┼──────────┼──────────┤
# │ 0  │ server-1           │ fork     │ 0    │ online    │ 0%       │ 37.4mb   │
# │ 1  │ server-2           │ fork     │ 0    │ online    │ 0%       │ 37.2mb   │
# │ 2  │ server-3           │ fork     │ 0    │ online    │ 0%       │ 37.1mb   │
# └────┴────────────────────┴──────────┴──────┴───────────┴──────────┴──────────┘
```

**Explicación:**

- `pm2 start ...`: Este comando le dice a PM2 que inicie los scripts de Node.js. PM2 se encargará de que se ejecuten y se mantengan activos.
- `pm2 list`: Muestra una lista de los procesos gestionados por PM2, para que puedas verificar que tus servidores están "online".

**Resultado:**
Con esto, tendrás tres servidores Node.js corriendo en tu máquina en las direcciones `localhost:3001`, `localhost:3002` y `localhost:3003` respectivamente.

## C - Configurando NGINX para Balanceo de Carga

Ahora viene la magia: decirle a NGINX que actúe como balanceador de carga para estos tres servidores.

#### 1. **Bloque `upstream`:**

**Definición:**
En la configuración de NGINX, `upstream` es como definir un grupo de servidores backend que trabajarán juntos. Piensa en ello como una "piscina" de servidores.

**Uso:**
Dentro del bloque `http` de tu configuración de NGINX, define un bloque `upstream` con un nombre (por ejemplo, `backend_servers`). Dentro de este bloque, lista los servidores que quieres balancear.

**Ejemplo de configuración `upstream`:**

```nginx
http {

    upstream backend_servers {
        server localhost:3001;
        server localhost:3002;
        server localhost:3003;
    }

    # ... (resto de la configuración http) ...
}
```

**Explicación:**

- `upstream backend_servers { ... }`: Define un grupo de servidores llamado `backend_servers`. Puedes elegir el nombre que quieras.
- `server localhost:3001;`: Cada línea `server` dentro del bloque `upstream` define la dirección de uno de tus servidores backend. Aquí estamos listando los tres servidores Node.js que arrancamos antes.

#### 2. **Bloque `server` y `location` con `proxy_pass`:**

**Definición:**
Ahora, necesitas decirle a NGINX que cuando reciba peticiones a tu dominio (`nginx-handbook.test` en este caso), las envíe al grupo de servidores que definiste en el bloque `upstream`. Esto se hace con la directiva `proxy_pass` dentro de un bloque `location`.

**Ejemplo de configuración `server`:**

```nginx
http {

    upstream backend_servers {
        server localhost:3001;
        server localhost:3002;
        server localhost:3003;
    }

    server {
        listen 80;
        server_name nginx-handbook.test;

        location / {
            proxy_pass http://backend_servers;
        }
    }
}
```

**Explicación:**

- `location / { ... }`: Configura qué hacer con las peticiones que llegan a la raíz (`/`) de tu dominio.
- `proxy_pass http://backend_servers;`: Esta es la clave. Le dice a NGINX que envíe (haga proxy) todas las peticiones a la dirección `http://backend_servers`. ¡Pero `backend_servers` no es una dirección real! Es el nombre del bloque `upstream` que definimos antes. NGINX entiende que debe distribuir las peticiones entre los servidores listados en ese bloque `upstream`.

**En resumen:**
Cuando alguien visite `http://nginx-handbook.test`, NGINX tomará la petición y la enviará a uno de los servidores en `backend_servers` (localhost:3001, localhost:3002 o localhost:3003) de forma balanceada.

## D - Probando el Balanceo de Carga

¡Es hora de ver si funciona! Vamos a enviar muchas peticiones a tu servidor NGINX y ver si las reparte entre los tres servidores Node.js.

#### 1. **Comando `curl` en un bucle:**

**Comando:**
Abre otra terminal y ejecuta este comando:

```bash
while sleep 0.5; do curl http://nginx-handbook.test; done
```

**Explicación:**

- `while sleep 0.5; do ... ; done`: Esto crea un bucle infinito en bash.
- `sleep 0.5`: Hace una pausa de 0.5 segundos en cada iteración del bucle.
- `curl http://nginx-handbook.test`: Envía una petición a tu servidor NGINX (que configuraste con el nombre `nginx-handbook.test`).

**Resultado esperado:**
Verás en la terminal respuestas como estas, ¡pero en diferente orden!

```
# response from server - 2.
# response from server - 3.
# response from server - 1.
# response from server - 2.
# response from server - 3.
# response from server - 1.
# response from server - 2.
# response from server - 3.
# response from server - 1.
# response from server - 2.
```

**¿Qué significa esto?**
Cada vez que `curl` envía una petición, NGINX la está enviando a un servidor diferente del grupo `backend_servers`. ¡Estás viendo el balanceo de carga en acción! NGINX está rotando las peticiones entre `server-1`, `server-2` y `server-3`.

#### 2. **Detener el bucle:**

Para parar el bucle, simplemente presiona `Ctrl + C` en la terminal.

## E - Deteniendo los Servidores Demo

¡No olvides apagar los servidores Node.js cuando termines de experimentar!

#### 1. **Comando para detener los servidores:**

```bash
pm2 stop server-1 server-2 server-3
```

**Explicación:**
Este comando le dice a PM2 que detenga los procesos llamados `server-1`, `server-2` y `server-3`.

**¡Listo!**
